{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skillettonchik/Skillettonchik/blob/main/%22Telegram_%D0%91%D0%BE%D1%82_%D1%81_ChatGPT_%D0%BD%D0%B0_%D0%B1%D0%BE%D1%80%D1%82%D1%83%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используя знания из [первой части](https://colab.research.google.com/drive/1tqXt0XNstMb2TeJ8Za9S2xQA6ipjyMPk) урока, а также базы знаний, полученной в [практической части](https://colab.research.google.com/drive/1GmRiwmUH8E8KJ4d1g8vDVMGSdfmFFjd5) урока, создайте телеграм-бот, который будет отвечать на вопросы из вашей базы знаний. Для создания телеграм-бота используйте библиотеку aiogram3. При отправке Telegram-боту команды `/help` он должен возвращать информацию о базе знаний: тематика, число записей в базе знаний, пример запроса к базе. Задание выполните в Блокноте, для этого вам необходимо вспомнить, как запустить асинхронный цикл в Google Colab.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c6WZSsChNoIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Отключим предупреждения в колабе. Будет меньше лишней информации в выводе\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bHo8sLyQ4aX",
        "outputId": "43f0215b-4be2-4cf2-e404-b02cb8cb63ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai mwclient mwparserfromhell tiktoken aiogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KdFayyGIXPs",
        "outputId": "cc951ceb-ffb5-4c42-8b80-e21a00afe569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Requirement already satisfied: mwclient in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: mwparserfromhell in /usr/local/lib/python3.11/dist-packages (0.6.6)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: aiogram in /usr/local/lib/python3.11/dist-packages (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from mwclient) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: aiofiles<24.2,>=23.2.1 in /usr/local/lib/python3.11/dist-packages (from aiogram) (24.1.0)\n",
            "Requirement already satisfied: aiohttp<3.12,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from aiogram) (3.11.11)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from aiogram) (2024.12.14)\n",
            "Requirement already satisfied: magic-filter<1.1,>=1.0.12 in /usr/local/lib/python3.11/dist-packages (from aiogram) (1.0.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->mwclient) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import mwclient  # библиотека для работы с MediaWiki API для загрузки примеров статей Википедии\n",
        "import mwparserfromhell  # Парсер для MediaWiki\n",
        "import openai  # будем использовать для токинизации\n",
        "import pandas as pd  # В DataFrame будем хранить базу знаний и результат токинизации базы знаний\n",
        "import re  # для вырезания ссылок <ref> из статей Википедии\n",
        "import tiktoken  # для подсчета токенов"
      ],
      "metadata": {
        "id": "RQBDlEn-PR37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# поиск страниц Википедии о зимних Олимпийских играх 2022 года\n",
        "\n",
        "# Задаем категорию и англоязычную версию Википедии для поиска\n",
        "CATEGORY_TITLE = \"Category:2024 IIHF World Championship\"\n",
        "WIKI_SITE = \"en.wikipedia.org\"\n",
        "\n",
        "# Соберем заголовки всех статей\n",
        "def titles_from_category(\n",
        "    category: mwclient.listing.Category, # Задаем типизированный параметр категории статей\n",
        "    max_depth: int # Определяем глубину вложения статей\n",
        ") -> set[str]:\n",
        "    \"\"\"Возвращает набор заголовков страниц в данной категории Википедии и ее подкатегориях.\"\"\"\n",
        "    titles = set() # Используем множество для хранения заголовков статей\n",
        "    for cm in category.members(): # Перебираем вложенные объекты категории\n",
        "        if type(cm) == mwclient.page.Page: # Если объект является страницей\n",
        "            titles.add(cm.name) # в хранилище заголовков добавляем имя страницы\n",
        "        elif isinstance(cm, mwclient.listing.Category) and max_depth > 0: # Если объект является категорией и глубина вложения не достигла максимальной\n",
        "            deeper_titles = titles_from_category(cm, max_depth=max_depth - 1) # вызываем рекурсивно функцию для подкатегории\n",
        "            titles.update(deeper_titles) # добавление в множество элементов из другого множества\n",
        "    return titles\n",
        "\n",
        "# Инициализация объекта MediaWiki\n",
        "# WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "site = mwclient.Site(WIKI_SITE)\n",
        "\n",
        "# Загрузка раздела заданной категории\n",
        "category_page = site.pages[CATEGORY_TITLE]\n",
        "# Получение множества всех заголовков категории с вложенностью на один уровень\n",
        "titles = titles_from_category(category_page, max_depth=1)\n",
        "\n",
        "\n",
        "print(f\"Создано {len(titles)} заголовков статей в категории {CATEGORY_TITLE}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oegJsj1DR8Mf",
        "outputId": "b0f8322e-a471-42f5-fb3d-dbf93a4aecf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создано 6 заголовков статей в категории Category:2024 IIHF World Championship.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем секции, которые будут отброшены при парсинге статей\n",
        "SECTIONS_TO_IGNORE = [\n",
        "    \"See also\",\n",
        "    \"References\",\n",
        "    \"External links\",\n",
        "    \"Further reading\",\n",
        "    \"Footnotes\",\n",
        "    \"Bibliography\",\n",
        "    \"Sources\",\n",
        "    \"Citations\",\n",
        "    \"Literature\",\n",
        "    \"Footnotes\",\n",
        "    \"Notes and references\",\n",
        "    \"Photo gallery\",\n",
        "    \"Works cited\",\n",
        "    \"Photos\",\n",
        "    \"Gallery\",\n",
        "    \"Notes\",\n",
        "    \"References and sources\",\n",
        "    \"References and notes\",\n",
        "]"
      ],
      "metadata": {
        "id": "SgU86LTWTeOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция возвращает список всех вложенных секций для заданной секции страницы Википедии\n",
        "\n",
        "def all_subsections_from_section(\n",
        "    section: mwparserfromhell.wikicode.Wikicode, # текущая секция\n",
        "    parent_titles: list[str], # Заголовки родителя\n",
        "    sections_to_ignore: set[str], # Секции, которые необходимо проигнорировать\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из раздела Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "\n",
        "    # Извлекаем заголовки текущей секции\n",
        "    headings = [str(h) for h in section.filter_headings()]\n",
        "    title = headings[0]\n",
        "    # Заголовки Википедии имеют вид: \"== Heading ==\"\n",
        "\n",
        "    if title.strip(\"=\" + \" \") in sections_to_ignore:\n",
        "        # Если заголовок секции в списке для игнора, то пропускаем его\n",
        "        return []\n",
        "\n",
        "    # Объединим заголовки и подзаголовки, чтобы сохранить контекст для chatGPT\n",
        "    titles = parent_titles + [title]\n",
        "\n",
        "    # Преобразуем wikicode секции в строку\n",
        "    full_text = str(section)\n",
        "\n",
        "    # Выделяем текст секции без заголовка\n",
        "    section_text = full_text.split(title)[1]\n",
        "    if len(headings) == 1:\n",
        "        # Если один заголовок, то формируем результирующий список\n",
        "        return [(titles, section_text)]\n",
        "    else:\n",
        "        first_subtitle = headings[1]\n",
        "        section_text = section_text.split(first_subtitle)[0]\n",
        "        # Формируем результирующий список из текста до первого подзаголовка\n",
        "        results = [(titles, section_text)]\n",
        "        for subsection in section.get_sections(levels=[len(titles) + 1]):\n",
        "            results.extend(\n",
        "                # Вызываем функцию получения вложенных секций для заданной секции\n",
        "                all_subsections_from_section(subsection, titles, sections_to_ignore)\n",
        "                )  # Объединяем результирующие списки данной функции и вызываемой\n",
        "        return results\n",
        "\n",
        "# Функция возвращает список всех секций страницы, за исключением тех, которые отбрасываем\n",
        "def all_subsections_from_title(\n",
        "    title: str, # Заголовок статьи Википедии, которую парсим\n",
        "    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE, # Секции, которые игнорируем\n",
        "    site_name: str = WIKI_SITE, # Ссылка на сайт википедии\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из заголовка страницы Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "\n",
        "    # Инициализация объекта MediaWiki\n",
        "    # WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "    site = mwclient.Site(site_name)\n",
        "\n",
        "    # Запрашиваем страницу по заголовку\n",
        "    page = site.pages[title]\n",
        "\n",
        "    # Получаем текстовое представление страницы\n",
        "    text = page.text()\n",
        "\n",
        "    # Удобный парсер для MediaWiki\n",
        "    parsed_text = mwparserfromhell.parse(text)\n",
        "    # Извлекаем заголовки\n",
        "    headings = [str(h) for h in parsed_text.filter_headings()]\n",
        "    if headings: # Если заголовки найдены\n",
        "        # В качестве резюме берем текст до первого заголовка\n",
        "        summary_text = str(parsed_text).split(headings[0])[0]\n",
        "    else:\n",
        "        # Если нет заголовков, то весь текст считаем резюме\n",
        "        summary_text = str(parsed_text)\n",
        "    results = [([title], summary_text)] # Добавляем резюме в результирующий список\n",
        "    for subsection in parsed_text.get_sections(levels=[2]): # Извлекаем секции 2-го уровня\n",
        "        results.extend(\n",
        "            # Вызываем функцию получения вложенных секций для заданной секции\n",
        "            all_subsections_from_section(subsection, [title], sections_to_ignore)\n",
        "        ) # Объединяем результирующие списки данной функции и вызываемой\n",
        "    return results"
      ],
      "metadata": {
        "id": "eTKjRUVSTmUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбивка статей на секции\n",
        "# придется немного подождать, так как на парсинг 100 статей требуется около минуты\n",
        "wikipedia_sections = []\n",
        "for title in titles:\n",
        "    wikipedia_sections.extend(all_subsections_from_title(title))\n",
        "print(f\"Найдено {len(wikipedia_sections)} секций на {len(titles)} страницах\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDzevmFsT4CD",
        "outputId": "e3a2c2ef-6538-4dbe-cdd5-6176b8778bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено 118 секций на 6 страницах\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Очистка текста секции от ссылок <ref>xyz</ref>, начальных и конечных пробелов\n",
        "def clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n",
        "    titles, text = section\n",
        "    # Удаляем ссылки\n",
        "    text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
        "    # Удаляем пробелы вначале и конце\n",
        "    text = text.strip()\n",
        "    return (titles, text)\n",
        "\n",
        "# Применим функцию очистки ко всем секциям с помощью генератора списков\n",
        "wikipedia_sections = [clean_section(ws) for ws in wikipedia_sections]\n",
        "\n",
        "# Отфильтруем короткие и пустые секции\n",
        "def keep_section(section: tuple[list[str], str]) -> bool:\n",
        "    \"\"\"Возвращает значение True, если раздел должен быть сохранен, в противном случае значение False.\"\"\"\n",
        "    titles, text = section\n",
        "    # Фильтруем по произвольной длине, можно выбрать и другое значение\n",
        "    if len(text) < 16:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "original_num_sections = len(wikipedia_sections)\n",
        "wikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\n",
        "print(f\"Отфильтровано {original_num_sections-len(wikipedia_sections)} секций, осталось {len(wikipedia_sections)} секций.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_70u40SWUJ_8",
        "outputId": "eac41ef4-8ae2-4f48-da26-bcae28a9ed2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отфильтровано 5 секций, осталось 113 секций.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ws in wikipedia_sections[:5]:\n",
        "    print(ws[0])\n",
        "    display(ws[1][:50] + \"...\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6rUdZeE2ULvg",
        "outputId": "db93c589-3f32-4d2a-9108-8d2ce4d6007e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2024 IIHF World Championship Group A']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Short description|International ice hockey resul...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['2024 IIHF World Championship Group A', '==Standings==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'<onlyinclude>{{#invoke:Sports table|main|style=WL ...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['2024 IIHF World Championship Group A', '==Matches==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"''All times are local ([[Time in the Czech Republi...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['2024 IIHF World Championship Group A', '==Matches==', '===Switzerland vs Norway===']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Ice hockey box\\n|bg         = \\n|date       = 10 M...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['2024 IIHF World Championship Group A', '==Matches==', '===Czechia vs Finland===']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Ice hockey box\\n|bg         = \\n|date       = 10 M...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = \"gpt-3.5-turbo\"  # only matters insofar as it selects which tokenizer to use\n",
        "\n",
        "# Функция подсчета токенов\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Возвращает число токенов в строке.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# Функция разделения строк\n",
        "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
        "    \"\"\"Разделяет строку надвое с помощью разделителя (delimiter), пытаясь сбалансировать токены с каждой стороны.\"\"\"\n",
        "\n",
        "    # Делим строку на части по разделителю, по умолчанию \\n - перенос строки\n",
        "    chunks = string.split(delimiter)\n",
        "    if len(chunks) == 1:\n",
        "        return [string, \"\"]  # разделитель не найден\n",
        "    elif len(chunks) == 2:\n",
        "        return chunks  # нет необходимости искать промежуточную точку\n",
        "    else:\n",
        "        # Считаем токены\n",
        "        total_tokens = num_tokens(string)\n",
        "        halfway = total_tokens // 2\n",
        "        # Предварительное разделение по середине числа токенов\n",
        "        best_diff = halfway\n",
        "        # В цикле ищем какой из разделителей, будет ближе всего к best_diff\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            left = delimiter.join(chunks[: i + 1])\n",
        "            left_tokens = num_tokens(left)\n",
        "            diff = abs(halfway - left_tokens)\n",
        "            if diff >= best_diff:\n",
        "                break\n",
        "            else:\n",
        "                best_diff = diff\n",
        "        left = delimiter.join(chunks[:i])\n",
        "        right = delimiter.join(chunks[i:])\n",
        "        # Возвращаем левую и правую часть оптимально разделенной строки\n",
        "        return [left, right]\n",
        "\n",
        "\n",
        "# Функция обрезает строку до максимально разрешенного числа токенов\n",
        "def truncated_string(\n",
        "    string: str, # строка\n",
        "    model: str, # модель\n",
        "    max_tokens: int, # максимальное число разрешенных токенов\n",
        "    print_warning: bool = True, # флаг вывода предупреждения\n",
        ") -> str:\n",
        "    \"\"\"Обрезка строки до максимально разрешенного числа токенов.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    encoded_string = encoding.encode(string)\n",
        "    # Обрезаем строку и декодируем обратно\n",
        "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
        "    if print_warning and len(encoded_string) > max_tokens:\n",
        "        print(f\"Предупреждение: Строка обрезана с {len(encoded_string)} токенов до {max_tokens} токенов.\")\n",
        "    # Усеченная строка\n",
        "    return truncated_string\n",
        "\n",
        "# Функция делит секции статьи на части по максимальному числу токенов\n",
        "def split_strings_from_subsection(\n",
        "    subsection: tuple[list[str], str], # секции\n",
        "    max_tokens: int = 1000, # максимальное число токенов\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    max_recursion: int = 5, # максимальное число рекурсий\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Разделяет секции на список из частей секций, в каждой части не более max_tokens.\n",
        "    Каждая часть представляет собой кортеж родительских заголовков [H1, H2, ...] и текста (str).\n",
        "    \"\"\"\n",
        "    titles, text = subsection\n",
        "    string = \"\\n\\n\".join(titles + [text])\n",
        "    num_tokens_in_string = num_tokens(string)\n",
        "    # Если длина соответствует допустимой, то вернет строку\n",
        "    if num_tokens_in_string <= max_tokens:\n",
        "        return [string]\n",
        "    # если в результате рекурсия не удалось разделить строку, то просто усечем ее по числу токенов\n",
        "    elif max_recursion == 0:\n",
        "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        "    # иначе разделим пополам и выполним рекурсию\n",
        "    else:\n",
        "        titles, text = subsection\n",
        "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]: # Пробуем использовать разделители от большего к меньшему (разрыв, абзац, точка)\n",
        "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
        "            if left == \"\" or right == \"\":\n",
        "                # если какая-либо половина пуста, повторяем попытку с более простым разделителем\n",
        "                continue\n",
        "            else:\n",
        "                # применим рекурсию на каждой половине\n",
        "                results = []\n",
        "                for half in [left, right]:\n",
        "                    half_subsection = (titles, half)\n",
        "                    half_strings = split_strings_from_subsection(\n",
        "                        half_subsection,\n",
        "                        max_tokens=max_tokens,\n",
        "                        model=model,\n",
        "                        max_recursion=max_recursion - 1, # уменьшаем максимальное число рекурсий\n",
        "                    )\n",
        "                    results.extend(half_strings)\n",
        "                return results\n",
        "    # иначе никакого разделения найдено не было, поэтому просто обрезаем строку (должно быть очень редко)\n",
        "    return [truncated_string(string, model=model, max_tokens=max_tokens)]"
      ],
      "metadata": {
        "id": "J2LCvCE1UhW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Делим секции на части\n",
        "MAX_TOKENS = 1600\n",
        "wikipedia_strings = []\n",
        "for section in wikipedia_sections:\n",
        "    wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
        "\n",
        "print(f\"{len(wikipedia_sections)} секций Википедии поделены на {len(wikipedia_strings)} строк.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLWJk8l8UkBz",
        "outputId": "f0bd5eee-9a18-48fc-b836-46a79c9a3fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113 секций Википедии поделены на 149 строк.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Напечатаем пример строки\n",
        "print(wikipedia_strings[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpX5QrRuU06Y",
        "outputId": "66aef818-c117-4681-c3c6-c3a5d42bf36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024 IIHF World Championship Group A\n",
            "\n",
            "==Standings==\n",
            "\n",
            "<onlyinclude>{{#invoke:Sports table|main|style=WL OT\n",
            "|update=complete\n",
            "|source=[https://stats.iihf.com/Hydra/902/IHM902300_76_50_0.pdf IIHF]\n",
            "\n",
            "|team_order=CAN, SUI, CZE, FIN, AUT, NOR, DEN, GBR\n",
            "\n",
            "|win_CAN=5 |OTwin_CAN=2 |OTloss_CAN=0 |loss_CAN=0 |gf_CAN=32|ga_CAN=18\n",
            "|win_FIN=3 |OTwin_FIN=0 |OTloss_FIN=1 |loss_FIN=3 |gf_FIN=21|ga_FIN=14\n",
            "|win_SUI=5 |OTwin_SUI=1 |OTloss_SUI=0 |loss_SUI=1 |gf_SUI=29|ga_SUI=12\n",
            "|win_CZE=4 |OTwin_CZE=1 |OTloss_CZE=2 |loss_CZE=0 |gf_CZE=26|ga_CZE=14|status_CZE=H\n",
            "|win_DEN=2 |OTwin_DEN=0 |OTloss_DEN=0 |loss_DEN=5 |gf_DEN=15|ga_DEN=29\n",
            "|win_NOR=2 |OTwin_NOR=0 |OTloss_NOR=0 |loss_NOR=5 |gf_NOR=15|ga_NOR=25\n",
            "|win_AUT=2 |OTwin_AUT=0 |OTloss_AUT=1 |loss_AUT=4 |gf_AUT=21|ga_AUT=29\n",
            "|win_GBR=1 |OTwin_GBR=0 |OTloss_GBR=0 |loss_GBR=6 |gf_GBR=12|ga_GBR=30\n",
            "\n",
            "|hth_NOR=Denmark 0–2 Norway\n",
            "|hth_DEN=NOR\n",
            "\n",
            "|name_CAN={{ih|CAN}}\n",
            "|name_FIN={{ih|FIN}}\n",
            "|name_SUI={{ih|SUI}}\n",
            "|name_CZE={{ih|CZE|name=Czechia}}\n",
            "|name_DEN={{ih|DEN}}\n",
            "|name_NOR={{ih|NOR}}\n",
            "|name_AUT={{ih|AUT}}\n",
            "|name_GBR={{ih|GBR}}\n",
            "\n",
            "|class_rules = 1) points; 2) head-to-head points; 3) head-to-head goal difference; 4) head-to-head number of goals scored; 5) result against closest best-ranked team outside tied teams; 6) result against second-best-ranked team outside tied teams; 7) seeding before tournament\n",
            "\n",
            "|result1=Q |result2=Q |result3=Q |result4=Q |result5=S |result6=S |result7=S |result8=REL\n",
            "\n",
            "|res_col_header=QR\n",
            "|col_Q=green1 |text_Q=[[2024 IIHF World Championship playoff round|Quarterfinals]]\n",
            "|col_S=white1 |text_S=Qualification for [[2025 IIHF World Championship]]\n",
            "|col_REL=red1 |text_REL=Relegation to [[2025 IIHF World Championship Division I|2025 Division I A]]\n",
            "}}</onlyinclude>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # Модель токенизации от OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")\n",
        "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Функция отправки chatGPT строки для ее токенизации (вычисления эмбедингов)\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "\n",
        "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn2aB1OmU4A0",
        "outputId": "f583fa73-3331-4378-a2a0-a10dbcdb50d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"text\": wikipedia_strings})\n",
        "df['embedding'] = df.text.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
        "\n",
        "SAVE_PATH = \"./euro_2024.csv\"\n",
        "# Сохранение результата\n",
        "df.to_csv(SAVE_PATH, index=False)"
      ],
      "metadata": {
        "id": "V870ji6eXCys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "I3OAAoAOXIu3",
        "outputId": "0e798aad-b6e3-4bb7-c52f-5ea42877c74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "144  2024 IIHF World Championship playoff round\\n\\n...   \n",
              "145  2024 IIHF World Championship playoff round\\n\\n...   \n",
              "146  2024 IIHF World Championship playoff round\\n\\n...   \n",
              "147  2024 IIHF World Championship playoff round\\n\\n...   \n",
              "148  2024 IIHF World Championship playoff round\\n\\n...   \n",
              "\n",
              "                                             embedding  \n",
              "144  [-0.011156370863318443, -0.014673909172415733,...  \n",
              "145  [-0.0029648696072399616, -0.013514135964214802...  \n",
              "146  [-0.0017023817636072636, -0.007638164330273867...  \n",
              "147  [-0.022531673312187195, -0.010496951639652252,...  \n",
              "148  [-0.011626380495727062, 0.0021273382008075714,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb4f8a93-a7d8-478b-9c68-70207ddb2623\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>2024 IIHF World Championship playoff round\\n\\n...</td>\n",
              "      <td>[-0.011156370863318443, -0.014673909172415733,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>2024 IIHF World Championship playoff round\\n\\n...</td>\n",
              "      <td>[-0.0029648696072399616, -0.013514135964214802...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2024 IIHF World Championship playoff round\\n\\n...</td>\n",
              "      <td>[-0.0017023817636072636, -0.007638164330273867...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2024 IIHF World Championship playoff round\\n\\n...</td>\n",
              "      <td>[-0.022531673312187195, -0.010496951639652252,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2024 IIHF World Championship playoff round\\n\\n...</td>\n",
              "      <td>[-0.011626380495727062, 0.0021273382008075714,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb4f8a93-a7d8-478b-9c68-70207ddb2623')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb4f8a93-a7d8-478b-9c68-70207ddb2623 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb4f8a93-a7d8-478b-9c68-70207ddb2623');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1303580-c771-4d66-be35-7d5d4aa468e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1303580-c771-4d66-be35-7d5d4aa468e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1303580-c771-4d66-be35-7d5d4aa468e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2024 IIHF World Championship playoff round\\n\\n==Semifinals==\\n\\n===Sweden vs Czechia===\\n\\n{{Ice hockey box\\n|bg         = \\n|date       = 25 May 2024\\n|time       = 14:20\\n|team1      = {{ih-rt|SWE}}\\n|team2      = '''{{ih|CZE|name=Czechia}}'''\\n|score      = 3\\u20137\\n|progression= 1\\u20130 / 1\\u20131 / 2\\u20131 / 2\\u20132 / 2\\u20133 / 2\\u20134 / 2\\u20135 / 3\\u20135 / 3\\u20136 / 3\\u20137\\n|periods    = (2\\u20132, 1\\u20133, 0\\u20132)\\n|goalie1    = [[Filip Gustavsson]]<br>[[Samuel Ersson]]\\n|goalie2    = [[Luk\\u00e1\\u0161 Dost\\u00e1l]]\\n|goals1     = [[Marcus Johansson (ice hockey, born 1990)|Johansson]] \\u2013 03:39 / [[Marcus Pettersson|Pettersson]] ([[Adrian Kempe|Kempe]], [[Joel Eriksson Ek|Eriksson Ek]]) \\u2013 08:08 / Eriksson Ek ([[Lucas Raymond|Raymond]], [[Rasmus Dahlin|Dahlin]]) (PP) \\u2013 35:30\\n|goals2     = 07:48 \\u2013 [[Dominik Kubal\\u00edk|Kubal\\u00edk]] ([[Martin Ne\\u010das|Ne\\u010das]], [[Tom\\u00e1\\u0161 Kundr\\u00e1tek|Kundr\\u00e1tek]]) / 09:37 \\u2013 [[David K\\u00e4mpf|K\\u00e4mpf]] (Ne\\u010das) / 26:05 \\u2013 [[Ond\\u0159ej Ka\\u0161e|Ka\\u0161e]] ([[Luk\\u00e1\\u0161 Sedl\\u00e1k|Sedl\\u00e1k]]) / 26:21 \\u2013 Ne\\u010das (Kubal\\u00edk, K\\u00e4mpf) / 29:03 \\u2013 Kubal\\u00edk ([[Michal Kempn\\u00fd|Kempn\\u00fd]], Ne\\u010das) / 45:40 \\u2013 Sedl\\u00e1k (Ka\\u0161e) / 53:42 \\u2013 Sedl\\u00e1k\\n|stadium    = [[O2 Arena (Prague)|O2 Arena]], [[Prague]]\\n|attendance = 17,413\\n|official   = {{flagicon|LAT}} Andris Ansons\\n|official2  = {{flagicon|FIN}} Kristian Vikman\\n|linesman   = {{flagicon|USA}} Kevin Briganti\\n|linesman2  = {{flagicon|USA}} Nick Briganti\\n|reference  = https://stats.iihf.com/hydra/902/ihm902261_74_3_0.pdf\\n|penalties1 = 6\\n|penalties2 = 12\\n|shots1     = 40\\n|shots2     = 23\\n}}\",\n          \"2024 IIHF World Championship playoff round\\n\\n==Gold medal game==\\n\\n{{main|2024 IIHF World Championship final}}\\n{{:2024 IIHF World Championship final}}\",\n          \"2024 IIHF World Championship playoff round\\n\\n==Semifinals==\\n\\n===Canada vs Switzerland===\\n\\n{{Ice hockey box\\n|bg         = \\n|date       = 25 May 2024\\n|time       = 18:20\\n|team1      = {{ih-rt|CAN}}\\n|team2      = '''{{ih|SUI}}'''\\n|score      = 2\\u20133 {{small|[[Overtime (ice hockey)#Shootout|GWS]]}}\\n|progression= 0\\u20131 / 0\\u20132 / 1\\u20132 / 2\\u20132\\n|periods    = (0\\u20132, 1\\u20130, 1\\u20130)<br>(OT: 0\\u20130)<br>(SO: 0\\u20131)\\n|goalie1    = [[Jordan Binnington]]\\n|goalie2    = [[Leonardo Genoni]]\\n|goals1     = [[Brandon Tanev|Tanev]] ([[Olen Zellweger|Zellweger]], [[Pierre-Luc Dubois|Dubois]]) \\u2013 34:07 / [[John Tavares|Tavares]] ([[Connor Bedard|Bedard]], [[Owen Power|Power]]) (PP) \\u2013 57:53\\n|goals2     = 15:06 \\u2013 [[Kevin Fiala|Fiala]] ([[Romain Loeffel|Loeffel]], [[Sven Andrighetto|Andrighetto]]) (PP) / 17:16 \\u2013 [[Nino Niederreiter|Niederreiter]] ([[Roman Josi|Josi]], Fiala) (PP)\\n|soshots1   = Bedard {{SOgoal}} / Dubois {{SOmiss}} / [[Damon Severson|Severson]] {{SOmiss}} / Power {{SOmiss}} / [[Dylan Cozens (ice hockey)|Cozens]] {{SOmiss}}\\n|soshots2   = {{SOmiss}} [[Sven Senteler|Senteler]] / {{SOgoal}} Fiala / {{SOmiss}} Loeffel / {{SOgoal}} [[Sven Andrighetto|Andrighetto]] \\n|stadium    = [[O2 Arena (Prague)|O2 Arena]], [[Prague]]\\n|attendance = 11,159\\n|official   = {{flagicon|SWE}} Mikael Holm\\n|official2  = {{flagicon|CZE}} Jan Hribik\\n|linesman   = {{flagicon|SWE}} Ludvig Lundgren\\n|linesman2  = {{flagicon|CZE}} Josef \\u0160p\\u016fr\\n|reference  = https://stats.iihf.com/Hydra/902/IHM902262_74_5_0.pdf\\n|penalties1 = 12\\n|penalties2 = 10\\n|shots1     = 44\\n|shots2     = 31\\n}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial  # вычисляет сходство векторов\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "# Функция поиска\n",
        "def strings_ranked_by_relatedness(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), # функция схожести, косинусное расстояние\n",
        "    top_n: int = 100 # выбор лучших n-результатов\n",
        ") -> tuple[list[str], list[float]]: # Функция возвращает кортеж двух списков, первый содержит строки, второй - числа с плавающей запятой\n",
        "    \"\"\"Возвращает строки и схожести, отсортированные от большего к меньшему\"\"\"\n",
        "\n",
        "    # Отправляем в OpenAI API пользовательский запрос для токенизации\n",
        "    query_embedding_response = openai.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,\n",
        "    )\n",
        "\n",
        "    # Получен токенизированный пользовательский запрос\n",
        "    query_embedding = query_embedding_response.data[0].embedding\n",
        "\n",
        "    # Сравниваем пользовательский запрос с каждой токенизированной строкой DataFrame\n",
        "    strings_and_relatednesses = [\n",
        "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
        "        for i, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Сортируем по убыванию схожести полученный список\n",
        "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Преобразовываем наш список в кортеж из списков\n",
        "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
        "\n",
        "    # Возвращаем n лучших результатов\n",
        "    return strings[:top_n], relatednesses[:top_n]"
      ],
      "metadata": {
        "id": "0gMqJO2nXY3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# с этой функцией мы уже знакомы\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Возвращает число токенов в строке для заданной модели\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# Функция формирования запроса к chatGPT по пользовательскому вопросу и базе знаний\n",
        "def query_message(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str, # модель\n",
        "    token_budget: int # ограничение на число отсылаемых токенов в модель\n",
        ") -> str:\n",
        "    \"\"\"Возвращает сообщение для GPT с соответствующими исходными текстами, извлеченными из фрейма данных (базы знаний).\"\"\"\n",
        "    strings, relatednesses = strings_ranked_by_relatedness(query, df) # функция ранжирования базы знаний по пользовательскому запросу\n",
        "    # Шаблон инструкции для chatGPT\n",
        "    message = 'Use the below articles on the 2022 Winter Olympics to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n",
        "    # Шаблон для вопроса\n",
        "    question = f\"\\n\\nQuestion: {query}\"\n",
        "\n",
        "    # Добавляем к сообщению для chatGPT релевантные строки из базы знаний, пока не выйдем за допустимое число токенов\n",
        "    for string in strings:\n",
        "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
        "        if (num_tokens(message + next_article + question, model=model) > token_budget):\n",
        "            break\n",
        "        else:\n",
        "            message += next_article\n",
        "    return message + question\n",
        "\n",
        "\n",
        "def ask(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame = df, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    token_budget: int = 4096 - 500, # ограничение на число отсылаемых токенов в модель\n",
        "    print_message: bool = False, # нужно ли выводить сообщение перед отправкой\n",
        ") -> str:\n",
        "    \"\"\"Отвечает на вопрос, используя GPT и базу знаний.\"\"\"\n",
        "    # Формируем сообщение к chatGPT (функция выше)\n",
        "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
        "    # Если параметр True, то выводим сообщение\n",
        "    if print_message:\n",
        "        print(message)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You answer questions about the 2022 Winter Olympics.\"},\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "    ]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0 # гиперпараметр степени случайности при генерации текста. Влияет на то, как модель выбирает следующее слово в последовательности.\n",
        "    )\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message"
      ],
      "metadata": {
        "id": "hqvfVSLqXh__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask('who won the 2024 IIHF World Championship?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vd6H2So5X6et",
        "outputId": "f8eb353a-8489-40f4-903f-6ee230158c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Czechia won the 2024 IIHF World Championship.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask('кто выиграл чемпионат мира по хоккею с шайбой 2024 года?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RVrhFOjVbcrq",
        "outputId": "07a36a9b-7478-4bd2-9f91-7fa86411faf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Чемпионат мира по хоккею с шайбой 2024 года выиграла сборная Чехии.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters import Command\n",
        "from aiogram.types import Message\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Токен вашего бота\n",
        "BOT_TOKEN = \"7738546763:AAEQo3UpR_8S5N_vQWkh9TZDyz8aFqK4ulM\"\n",
        "\n",
        "# Создаем объект бота и диспетчера\n",
        "bot = Bot(token=BOT_TOKEN)\n",
        "dp = Dispatcher()\n",
        "total_records = len(df)\n",
        "@dp.message(Command(\"help\"))\n",
        "async def help_command(message: Message):\n",
        "    try:\n",
        "\n",
        "\n",
        "        response = (\n",
        "            \"📚 Информация о базе знаний:\\n\"\n",
        "            f\"- Тематика: Чемпионат мира по хоккею с шайбой 2024\\n\"\n",
        "            f\"- Количество записей: {total_records}\\n\"\n",
        "            f\"- Пример запроса:\\n\"\n",
        "            f\"- Кто одержал победу в финале Чемпионата мира по хоккею?\"\n",
        "        )\n",
        "        await message.answer(response)\n",
        "    except Exception as e:\n",
        "        await message.answer(f\"Произошла ошибка: {str(e)}\")\n",
        "\n",
        "\n",
        "\n",
        "@dp.message()\n",
        "async def answer_query(message: Message):\n",
        "    query = message.text.strip()\n",
        "    answer =  ask(query)\n",
        "    await message.answer(answer)\n",
        "\n",
        "\n",
        "async def main():\n",
        "    print(\"Start bot....\")\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaE7qzK8b2ka",
        "outputId": "44f45063-cbb3-4b28-9a1d-b46b941f0dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start bot....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:aiogram.dispatcher:Failed to fetch updates - TelegramNetworkError: HTTP Client says - ClientOSError: [Errno 104] Connection reset by peer\n",
            "WARNING:aiogram.dispatcher:Sleep for 1.000000 seconds and try again... (tryings = 0, bot id = 7738546763)\n",
            "ERROR:aiogram.dispatcher:Failed to fetch updates - TelegramNetworkError: HTTP Client says - ClientOSError: [Errno 104] Connection reset by peer\n",
            "WARNING:aiogram.dispatcher:Sleep for 1.000000 seconds and try again... (tryings = 0, bot id = 7738546763)\n"
          ]
        }
      ]
    }
  ]
}